<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>TensorRT + gunicorn + multi-threading，帶你飛起 • shytab</title><meta name="description" content="TensorRT + gunicorn + multi-threading，帶你飛起 - shytab"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.svg"><link rel="stylesheet" href="https://unpkg.com/nanoreset/nanoreset.min.css"><link rel="stylesheet" href="/css/theme.css"><link rel="search" type="application/opensearchdescription+xml" href="/atom.xml" title="shytab"></head><body><div class="wrap" id="barba-wrapper"><header><h1 class="branding"><a href="/" title="shytab"><img class="logo-image" src="/logo.svg" alt="logo"></a></h1><ul class="nav nav-list"><li class="nav-list-item"><a class="nav-list-link no-barba" href="/" target="_self">HOME</a></li><li class="nav-list-item"><a class="nav-list-link no-barba" href="/archives" target="_self">ARCHIVES</a></li><li class="nav-list-item"><a class="nav-list-link no-barba" href="https://github.com/shytab" target="_blank">GITHUB</a></li><li class="nav-list-item"><a class="nav-list-link no-barba" href="/atom.xml" target="_self">RSS</a></li></ul></header><div class="barba-container"><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">TensorRT + gunicorn + multi-threading，帶你飛起</h1><div class="post-info"><a></a>2017-11-10</div><div class="post-content"><p><em>借助于tensorRT/gunicorn/multithreading，在单个M40机器上，Resnet101能够达到100+pcs/sec的处理速度。在我们的方案中需要下载和上传图像，如果只考虑inference的过程，实际可以达到400pcs/sec的理论速度。</em></p>
<div align="center"><br><img src="https://wx1.sinaimg.cn/mw1024/89ef5361gy1fld6h59d9bj20cm07vdh1.jpg" width="400" height="200"><br><br><font color="#0099ff" size="2"> each test finish 100 images’ download/upload/process</font><br></div>



<p><strong>Much Thanks to TensorRT Development Team!</strong></p>
<p>gunicorn 负责任务的分发，在多个模型instance之间调度任务。</p>
<p>TensorRT 除了速度快之外，对模型加载后的显存优化也使得同样的GPU计算环境允许加载更多instance(5个resnet27占用显存15% x 12G)，也就有了gunicorn更快的速度。当然实际测试中使用multi-threading后处理时间并非是instance数量的线性关系，而是达到速度上限后即使再多instance也无法再提升。</p>
<p>理论上来说，这应该是和thread的数量是有关系的。gunicorn+tensorRT也要受到线程最大并发数量的限制，如果没有网络通信对multi-threading的需求，改成本地处理，应当是满足线性的优化速度的。</p>
<p>PS: <font color="#995500"><strong>threading和multiprocess.pool.ThreadPool都有坑，前者无法唤起线程内的tensorRT调用，后者则很容易使用不当造成线程爆棚</strong></font></p>
</div></article></div></main><footer><div class="paginator"><a class="prev" href="/2017/11/29/porn-detection-test-results-on-self-benchmark-md/">prev</a><a class="next" href="/2017/10/13/2017-10-13-md/">next</a></div><div class="copyright"><p>&copy; 2018 <a href="http://yoursite.com">shytab</a><br>Powered by <a href="https://hexo.io/" rel="noreferrer" target="_blank">Hexo</a></p></div></footer></div></div><script src="https://cdnjs.cloudflare.com/ajax/libs/barba.js/1.0.0/barba.min.js"></script><script>document.addEventListener('DOMContentLoaded', function() {
    Barba.Pjax.start()
})</script></body></html>